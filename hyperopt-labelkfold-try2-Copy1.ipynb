{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import StratifiedKFold,KFold,train_test_split\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import LabelKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from scipy.io import mmread\n",
    "\n",
    "np.random.seed(333)\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.stdout = open('tune_hyperopt_try1.txt', 'w', 1)\n",
    "\n",
    "def cvtest(i,params,xgboost_prob,num_round):\n",
    "    \n",
    "    plst = list(params.items())\n",
    "    num_boost_round = num_round\n",
    "    # pass the indexes to your training and validation data\n",
    "\n",
    "    xgtrain = dtrain.slice(cv[i][0])\n",
    "    xgval = dtrain.slice(cv[i][1])\n",
    "\n",
    "    # define a watch list to observe the change in error f your training and holdout data\n",
    "\n",
    "    evals = [(xgtrain, 'train'), (xgval, 'eval')]\n",
    "\n",
    "    model = xgb.train(params, xgtrain, num_boost_round, early_stopping_rounds=30, evals=evals, verbose_eval=10)\n",
    "\n",
    "    #print (model.attributes())\n",
    "    print ('best ite:', model.best_iteration)\n",
    "    print ('best ntee:', model.best_ntree_limit)\n",
    "\n",
    "    pred_train = model.predict(xgval, ntree_limit = model.best_ntree_limit)\n",
    "    xgboost_prob[cv[i][1]] = pred_train\n",
    "    res = roc_auc_score(xgval.get_label(), pred_train)\n",
    "    return (res, model.best_iteration)\n",
    "\n",
    "def score(params):\n",
    "    print(\"Training with params : \")\n",
    "    print(params)\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['min_child_weight'] = int(params['min_child_weight'])\n",
    "    results_auc = np.repeat(0.0, k)\n",
    "    trees = np.repeat(0.0, k)\n",
    "    xgboost_prob = np.zeros(dtrain.num_row(), dtype=np.float64)\n",
    "    for i in range(k):\n",
    "        (results_auc[i], trees[i]) = cvtest(i,params,xgboost_prob,num_round)\n",
    "\n",
    "    score_auc = roc_auc_score(dtrain.get_label(), xgboost_prob)\n",
    "    score = 1 - score_auc\n",
    "    print(\"\\tAuc_kfold: {0}\".format(score_val))\n",
    "    print(\"\\tAuc_avg: {0}\".format(sum(results_auc)/len(results_auc)))\n",
    "    print(\"\\tTrees mean: {0}\".format(sum(trees)/len(trees)))\n",
    "    print(\"\\tTrees_kfold: {0}\\n\\n\".format(trees))\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(random_state=5):\n",
    "    space = {\n",
    "             'n_estimators' : 100000,\n",
    "             'eta' : 0.1,\n",
    "             'max_depth' : hp.quniform('max_depth', 2, 25, 1),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 12, 1),\n",
    "             'subsample' : hp.uniform('subsample', 0, 1),\n",
    "             'colsample_bytree' : hp.uniform('colsample_bytree', 0, 1),\n",
    "             'colsample_bylevel' : hp.uniform('colsample_bylevel', 0, 1),\n",
    "             'gamma' : hp.uniform('gamma', 0, 1),\n",
    "             'lambda': hp.uniform('lambda', 0, 5),\n",
    "             'alpha': hp.uniform('alpha', 0, 5),\n",
    "             'eval_metric': 'auc',\n",
    "             'objective': 'binary:logistic',\n",
    "             'nthread' : 16,\n",
    "             'silent' : 1,\n",
    "             'seed' : random_state\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, max_evals=250)\n",
    "\n",
    "    print(best)\n",
    "\n",
    "dtrain = xgb.DMatrix('svmlight_try2/dtrain.data')\n",
    "dtest = xgb.DMatrix('svmlight_try2/dtest.data')\n",
    "\n",
    "act_train_data = pd.read_csv(\"redhat_data_new/act_train_new_try2.csv\",dtype={'people_id': np.str, 'activity_id': np.str, 'outcome': np.int8}, parse_dates=['date'])\n",
    "\n",
    "k = 10\n",
    "cv = LabelKFold(act_train_data['people_id'], n_folds=k)\n",
    "cv = list(cv)\n",
    "\n",
    "#Trials object where the history of search will be stored\n",
    "trials = Trials()\n",
    "\n",
    "optimize()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
